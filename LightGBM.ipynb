{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "special-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unexpected-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dt.fread('/home/liuchh/kaggle/input/train_set.csv', sep='\\t').to_pandas()\n",
    "test_df = dt.fread('/home/liuchh/kaggle/input/test_a.csv', sep='\\t').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True, \n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,3),\n",
    "    max_features=3000)\n",
    "tfidf.fit(np.concatenate((train_df['text'].iloc[:].values,test_df['text'].iloc[:].values),axis=0))\n",
    "train_word_features = tfidf.transform(train_df['text'].iloc[:].values)\n",
    "test_word_features = tfidf.transform(test_df['text'].iloc[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_word_features\n",
    "y_train = train_df['label']\n",
    "X_test = test_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "KF = KFold(n_splits=5, random_state=7) \n",
    "\n",
    "clf = LGBMClassifier(n_jobs=-1, feature_fraction=0.7, bagging_fraction=0.4, lambda_l1=0.001, lambda_l2=0.01, n_estimators=600)\n",
    "\n",
    "# 存储测试集预测结果 行数：len(X_test) ,列数：1列\n",
    "test_pred = np.zeros((X_test.shape[0], 1), int)  \n",
    "for KF_index, (train_index,valid_index) in enumerate(KF.split(X_train)):\n",
    "    print('第', KF_index+1, '折交叉验证开始...')\n",
    "    # 训练集划分\n",
    "    x_train_, x_valid_ = X_train[train_index], X_train[valid_index]\n",
    "    y_train_, y_valid_ = y_train[train_index], y_train[valid_index]\n",
    "    # 模型构建\n",
    "    clf.fit(x_train_, y_train_)\n",
    "    # 模型预测\n",
    "    val_pred = clf.predict(x_valid_)\n",
    "    print(\"准确率为：\",f1_score(y_valid_, val_pred, average='macro'))\n",
    "    \n",
    "    # 保存测试集预测结果\n",
    "    test_pred = np.column_stack((test_pred, clf.predict(X_test)))  # 将矩阵按列合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, test_list in enumerate(test_pred):\n",
    "    preds.append(np.argmax(np.bincount(test_list)))\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/test_a_sample_submit.csv')\n",
    "submission['label'] = preds\n",
    "submission.to_csv('../output/LGBMClassifier_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
